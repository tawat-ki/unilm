# The Era of 1-bit LLMs

- Mar 20, 2024: release preprint [**The Era of 1-bit LLMs: Training Tips, Code and FAQ**](The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf)
- Feb 28, 2024: release preprint [(**BitNet b1.58**)) The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/abs/2402.17764)
- Oct 17, 2023: release preprint [**BitNet**: Scaling 1-bit Transformers for Large Language Models](https://arxiv.org/abs/2310.11453)

